# Changelog

All notable changes to Promptune will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased]

### Changed - Token-Based Effort Estimation (2025-10-27)

**Context:** Time-based estimates (hours/days) are poor metrics in AI-assisted parallel development where agents execute simultaneously. Tokens directly represent computational cost.

**Research Conducted:**

- Spawned 3 parallel research agents investigating:
  1. **Web Research:** Existing libraries (Anthropic Token Counting API, tiktoken, TokenCost, PreflightLLMCost)
  2. **Codebase Analysis:** Found existing token tracking in `observability_db.py` (prompt_tokens, completion_tokens, total_cost_usd)
  3. **Methodology Analysis:** Complexity multipliers (0.15√ó, 0.30√ó, 0.75√ó) and task-type output ratios (0.05-0.40√ó)

**Key Finding:** No industry-standard frameworks exist yet (emerging practice), but infrastructure is available and Promptune already tracks actual tokens.

**Architecture Designed:**

- Used `software-architect` skill to design complete token estimation system
- 5-phase implementation plan with 14 tasks
- Estimated effort: 95K tokens ($0.112 Haiku) or 22-32h sequential
- Created `docs/TOKEN_ESTIMATION_ARCHITECTURE.md` (748 lines)

**Components:**

1. Token Estimation Engine (context + reasoning + output formulas)
2. Database Schema Extension (task_estimates + calibration_history tables)
3. CLI Tools (estimate-tokens, accuracy-report)
4. Integration Layer (features.yaml scripts, /ctx:plan command)
5. Validation System (estimated vs actual comparison)
6. Calibration Engine (auto-adjust formulas based on 30-day rolling average)

**Formula:**

```
total_tokens = context + reasoning + output

Where:
  context = sum(file_tokens) + description_tokens
  reasoning = context √ó complexity_multiplier[0.15|0.30|0.75]
  output = context √ó output_ratio[0.05-0.40]
```

**Files Modified:**

- `CLAUDE.md` - Added comprehensive token estimation section with complexity tiers, cost calculations, best practices
- `features.yaml` - Converted all 15 features from hours to tokens with breakdown (context/reasoning/output) and costs
- `scripts/feature-status.py` - Display tokens with thousands separators and Haiku cost
- `scripts/feature-execute.py` - Show token breakdown table in implementation plans

**Impact:**

- Total project effort: 315K tokens = $0.366 (Haiku) vs $2.028 (Sonnet)
- Enables cost-aware decisions (model selection, parallelization)
- Foundation for real-time cost tracking and calibration
- Accuracy targets: ¬±15-20% (Month 1), ¬±10-15% (Month 3)

**Build vs Buy:**

- **BUY:** tiktoken (token counting), TokenCost (multi-model pricing) - both free
- **BUILD:** Output prediction heuristics, DB integration, calibration system

**Next Steps:**

1. Implement Phase 1 (foundation tasks: formulas, pricing config)
2. Extend observability_db.py schema (task_estimates table)
3. Build TokenEstimator class with estimation engine
4. Integrate with /ctx:plan for automatic task estimation
5. Collect data and validate accuracy after 2 weeks

**Discussion Note:** Confirmed that GitHub issues are redundant per `copilot-delegate/OLD_VS_NEW_DESIGN.md` - plan.yaml as single source of truth eliminates duplication and 60-80s setup overhead.

### Added - Decision Tracking System Design (2025-10-27)

**Context:** CHANGELOG maintenance is critical but current approach (import entire file) will bloat over time. Need scalable system to preserve context across sessions.

**Problem Identified:**

- CHANGELOG grows unbounded (after 1 year: 50K+ tokens)
- Mixing purposes: user-facing releases + developer decisions + AI context
- Poor queryability: chronological format hard to search
- No lifecycle: old decisions clutter forever

**Research Conducted:**

- ADR best practices (AWS, Google, Azure use this)
- AI assistant context preservation (Cursor, Copilot patterns)
- YAML vs Markdown for structured data
- Lifecycle management strategies

**Key Insight from User:** "Isn't YAML better for both human and AI readable while also programmable?"

- ‚úÖ Correct! YAML = structure + queryability + embedded Markdown
- Pattern already works: features.yaml successfully tracks 15 features
- Tools already exist: feature-status.py, feature-execute.py

**Architecture Designed:**

- `decisions.yaml` - Main database (like features.yaml)
  - Track 3 types: research, plans, decisions
  - Structured metadata + Markdown long-form text
  - Lifecycle rules: research (6 months), plans (90 days), decisions (forever)

- CLI Tools - Query and manage (copy feature-\*.py patterns)
  - `decision-search.py` - Filter by type/status/tags
  - `decision-add.py` - Interactive entry creation
  - `decision-report.py` - Auto-generate DECISION_INDEX.md
  - `decision-lifecycle.py` - Archive old entries

- Skill - Auto-track during conversations
  - Detects decision discussions automatically
  - Checks existing decisions before research (avoid $0.07 redundant work)
  - Appends new entries to decisions.yaml

- Hook - Session end reminder
  - Prompts to review decisions made

**Token Efficiency:**
| Time | CHANGELOG (all) | Decision System | Winner |
|------|-----------------|-----------------|--------|
| Month 1 | 5K | 5K | Tie |
| Year 1 | 50K | 10K | Decision (5√ó) |
| Year 5 | 150K | 10K | Decision (15√ó) |

**Lifecycle Strategy:**

- Research expires after 6 months (tech changes)
- Plans archive 90 days after completion
- Decisions never auto-archive (unless superseded)
- Quarterly archives: `docs/archive/decisions-2025-Q4.yaml`

**Scalability Plan:**

- Phase 1: Lifecycle + Tiering (0-100 entries, ~10K tokens)
- Phase 2: RAG integration (>100 entries, semantic search, <5K tokens always)
- Uses Model2Vec (already in Promptune!) for embeddings
- Vector DB: Chroma/LanceDB (free, local, no API)

**Design Optimization for /ctx:execute:**

- 95% copy existing patterns (features.yaml, feature-\*.py)
- Complete templates included in tasks (Haiku just copies)
- Independent tasks (full parallel execution)
- Zero ambiguity, zero creative decisions needed

**Implementation Plan Created:**

- Location: `.plans/decision-tracking-system/`
- 8 tasks across 3 phases
- Estimated: 60K tokens (Haiku), $0.070
- Execution: 2 phases parallel (30-45 min + 20-30 min)

**Files Created:**

- `.plans/decision-tracking-system/plan.yaml` - Complete execution plan
- `.plans/decision-tracking-system/tasks/task-1.md` - decisions.yaml schema with full template
- `.plans/decision-tracking-system/README.md` - Complete documentation

**Next Steps:**

1. Create remaining task files (tasks 2-8 with templates)
2. Execute: `/ctx:plan` ‚Üí `/ctx:execute`
3. Deploy as Promptune plugin feature (users get automatically)

**Future Enhancement:**
When >100 entries, add RAG for semantic search:

- "cost optimization" finds "token estimation" (semantic)
- Only load top 3 relevant (~2K tokens vs 60K)
- Token ceiling: ~5K max regardless of total entries

## [0.8.0] - 2025-10-25

### Changed

- **üéØ BREAKTHROUGH: Prompt Augmentation for Reliable Command Execution**
  - **Problem discovered**: Passive suggestions ([Promptune detected...]) had variable reliability
  - **Evidence**: Skills invoked via "use your X skill" work 100% reliably
  - **Solution**: Hook now uses `modifiedPrompt` to augment user's prompt with directive language
  - **Result**: Commands execute far more reliably via skill invocation

- **Prompt Augmentation Architecture:**

  ```python
  # Before (v0.7.x) - Passive suggestion
  hookOutput = {
      "additionalContext": "[Promptune detected: `/sc:design` with 85% confidence]"
  }

  # After (v0.8.0) - Active augmentation
  hookOutput = {
      "modifiedPrompt": "design a system. You can use your software-architect skill to help with this task."
  }
  ```

- **How It Works:**
  1. User types: "research best React libraries"
  2. Promptune detects: `/ctx:research` (95% keyword)
  3. Hook augments: Adds ". You can use your researcher skill to conduct this search."
  4. Claude receives augmented prompt ‚Üí Invokes skill reliably!

### Added

- **Skill Mapping System:**
  - `SKILL_MAPPING` dictionary maps commands ‚Üí skills
  - Skills use same namespace as commands for consistency:
    - `/sc:design` ‚Üí `sc:architect` (migrated, optimized)
    - `/sc:analyze` ‚Üí `sc:analyzer` (future)
    - `/ctx:research` ‚Üí `ctx:researcher` (NEW!)
    - `/ctx:plan` ‚Üí `ctx:planner` (future)

- **New Skills (Plugin-Local):**
  - **`ctx:researcher`** - Created `skills/researcher/SKILL.md`
    - Wraps `/ctx:research` command for reliable execution
    - Parallel research with 3 agents (web + codebase)
    - Structured output format with recommendations
    - Name matches command namespace (`ctx:`)

  - **`sc:architect`** - Migrated from global, optimized
    - Context-efficient version (27% reduction: 226‚Üí166 lines)
    - Same 5-step workflow: Understand ‚Üí Research ‚Üí Specify ‚Üí Decompose ‚Üí Plan
    - Wraps `/sc:design` command
    - Includes build vs. buy decision framework
    - All skills version controlled with plugin
    - Automatically available when plugin installed

- **`create_skill_augmented_prompt()` Function:**
  - Intelligently augments prompts based on detection
  - Uses skill directive for skill-backed commands
  - Falls back to command directive for others
  - Preserves user's original intent

### Benefits

- ‚úÖ **Much higher reliability** - Skills are first-class tools
- ‚úÖ **Better UX** - Commands "just work" more often
- ‚úÖ **Graceful degradation** - Falls back to commands if skill missing
- ‚úÖ **Evidence-based** - Proven in real conversation (software-architect invocation)
- ‚úÖ **Backward compatible** - Slash commands still work manually

### Technical Details

- Uses `modifiedPrompt` field in hook response (supported by Claude Code)
- Directive language: "You can use your X skill" (strong instruction)
- vs. Command language: "Please use the X command" (weaker)
- Skills invoked via Skill tool (structured, type-safe)
- Commands via text expansion (unstructured)

### Migration

- Automatic, no user action required
- Existing behavior enhanced, not replaced
- Slash commands still available for manual use
- Skills can be disabled if user prefers commands

## [0.7.0] - 2025-10-25

### Added

- **Unified Observability Database - Complete system instrumentation**
  - Expanded SQLite database to handle ALL observability data
  - New file: `lib/observability_db.py` - Comprehensive observability layer
  - New command: `ctx-dashboard.py` - Beautiful real-time dashboard
  - Database schema:
    - ‚úÖ `current_detection` - Active detection state (1 row)
    - ‚úÖ `detection_history` - All detections with full metadata
    - ‚úÖ `performance_metrics` - Component latency tracking (P50/P95/P99)
    - ‚úÖ `matcher_performance` - Per-tier matcher efficiency
    - ‚úÖ `error_logs` - Exception tracking with stack traces
    - ‚úÖ `sessions` - Session analytics
    - ‚úÖ `command_usage` - Usage patterns
    - ‚úÖ `user_patterns` - Custom preferences

- **Observability Dashboard Features:**
  - üìä Detection statistics (total, by method, by command)
  - ‚ö° Matcher performance (keyword/model2vec/semantic)
  - üìà System performance metrics (P50/P95/P99)
  - üîç Recent detections with timestamps
  - ‚ùå Error tracking with component breakdown
  - üè• System health score (0-100)
  - üí° Actionable recommendations

### Changed

- **Migration from `detections.db` to `observability.db`**
  - Renamed database file to reflect expanded scope
  - Single source of truth for all metrics
  - Updated all components to use unified DB:
    - `hooks/user_prompt_submit.py` - Writes detections + performance
    - `hooks/session_start.js` - Clears from observability.db
    - `~/.claude/statusline.sh` - Reads from observability.db

- **Enhanced Detection Tracking:**
  - Now logs matcher performance automatically
  - Tracks latency for each detection
  - Records prompt previews (first 60 chars)
  - Error logging with automatic retry

### Benefits

- ‚úÖ **Centralized**: No scattered JSON files
- ‚úÖ **Fast**: SQL queries for aggregations
- ‚úÖ **Correlations**: JOIN detection + performance + errors
- ‚úÖ **Time-series**: Built-in timestamp support
- ‚úÖ **Analytics-ready**: Foundation for ML insights

### Migration

- Automatic, no user action required
- Old `detections.db` ignored (can be safely deleted)
- New `observability.db` created on first use
- Zero breaking changes

## [0.6.0] - 2025-10-25

### Changed

- **Migrated from JSON files to SQLite for detection state management**
  - Replaced `.promptune/last_detection` (JSON) with `.promptune/detections.db` (SQLite)
  - Benefits:
    - ‚úÖ No file churn: Single UPDATE in-place instead of delete/create cycles
    - ‚úÖ Thread-safe: Built-in ACID transactions, no manual locking
    - ‚úÖ History tracking: `detection_history` table for statistics
    - ‚úÖ Atomic operations: Direct SQL queries vs read-parse-write
    - ‚úÖ Responsive: Status line queries SQLite directly (0.05-0.1ms)
  - Updated components:
    - `lib/detection_db.py` - New SQLite management class
    - `hooks/user_prompt_submit.py` - Uses DetectionDB instead of JSON
    - `hooks/session_start.js` - Clears detection from SQLite
    - `statusline.sh` - Queries SQLite with `sqlite3` CLI
  - Migration: Automatic, no user action required (old JSON files ignored)

### Added

- **Detection history tracking**
  - All detections stored in `detection_history` table
  - Statistics available via `DetectionDB.get_stats()`
  - Foundation for future analytics (/ctx:stats improvements)

## [0.5.5] - 2025-10-25

### Fixed

- **Session start hook now clears old detection state from status line**
  - Status line was showing stale detection from previous session
  - SessionStart hook now removes `.promptune/last_detection` file on startup
  - Status line displays clean state (no detection) until first detection in new session
  - Non-breaking change, gracefully handles missing detection file

## [0.5.4] - 2025-10-25

**Status: Rebrand to Promptune - Context Engineering Focus**

### Changed

**Major Rebrand:**

- **New name: Promptune** (formerly SlashSense)
  - Portmanteau: Context + Tune
  - Better represents core value proposition: context engineering
  - Domain: promptune.com (available)
  - Repository: github.com/promptunecc/promptune

**Command Name Changes:**

- `/ss:*` ‚Üí `/ctx:*` (shorter, clearer prefix)
  - `/ss:research` ‚Üí `/ctx:research`
  - `/ss:plan` ‚Üí `/ctx:plan`
  - `/ss:execute` ‚Üí `/ctx:execute`
  - `/ss:status` ‚Üí `/ctx:status`
  - `/ss:cleanup` ‚Üí `/ctx:cleanup`
  - `/ss:configure` ‚Üí `/ctx:configure`
  - `/ss:stats` ‚Üí `/ctx:stats`

**Updated Focus:**

- From: "Natural language to slash command mapping"
- To: "Precision-tuned context engineering"
- Emphasizes: Modular plans (95% fewer tokens), parallel workflows (81% cost reduction), zero-transformation architecture

**Files Updated:**

- `.claude-plugin/plugin.json` - Name, version (1.0.0), description
- All command files renamed: `ss-*.md` ‚Üí `ctx-*.md`
- All hooks updated: `hooks/user_prompt_submit.py`, `hooks/session_start.js`
- All skills updated: 4 skill SKILL.md files
- All agents updated: 5 agent .md files
- Configuration: `marketplace.json`, `intent_mappings.json`
- Documentation: All .md files in `docs/`, `.plans/`

### Migration

**For Existing Users:**

- Plugin name change: `slashsense` ‚Üí `promptune`
- Commands auto-remapped: Old `/ss:*` commands still work via intent detection
- No breaking changes to functionality
- See MIGRATION.md for detailed upgrade guide

### Version

- **Version bumped: 0.5.3 ‚Üí 0.5.4** (rebrand)
- Maintains experimental 0.x status
- All functionality preserved

## [0.5.3] - 2025-10-25

**Status: Zero-Context Command Discovery Release**

### Added

**SessionStart Hook for Command Discovery:**

- Added `hooks/session_start.js` - Displays Promptune commands at session start
- **Zero context overhead** - Uses `feedback` field (0 tokens, UI-only)
- Shows 7 key commands with descriptions
- Includes natural language examples
- Auto-displays on every session start, resume, clear, compact

### Benefits

**Context Optimization:**

- ‚úÖ **0 tokens** vs 150 tokens for CLAUDE.md manual approach
- ‚úÖ Command list visible to user without context cost
- ‚úÖ Auto-updates when plugin changes (no manual editing)
- ‚úÖ Works alongside Skills for comprehensive discovery

**User Experience:**

- ‚úÖ Commands shown at every session start
- ‚úÖ No setup required (works automatically)
- ‚úÖ Reinforces natural language usage patterns
- ‚úÖ Includes quick reference examples

**Architecture:**

- SessionStart hook: 0 tokens (feedback field)
- Skills: Contextual suggestions (when relevant)
- UserPromptSubmit: Intent detection (~20 tokens per match)
- **Total discovery overhead: ~20 tokens vs 150+ for static CLAUDE.md**

### Technical Details

**Hook Implementation:**

- Language: JavaScript (Node.js - guaranteed in Claude Code)
- Execution time: <10ms
- Output format: JSON with `feedback` field
- No `additionalContext` used (zero tokens)
- Registered in `hooks/hooks.json` under SessionStart event

**Comparison:**

| Approach              | Token Cost      | User Sees        | Auto-Updates |
| --------------------- | --------------- | ---------------- | ------------ |
| **SessionStart hook** | **0 tokens** ‚úÖ | ‚úÖ Every session | ‚úÖ Yes       |
| CLAUDE.md (manual)    | 150 tokens ‚ö†Ô∏è   | ‚úÖ Always        | ‚ùå Manual    |
| Skills only           | 0 tokens ‚úÖ     | ‚ö†Ô∏è Contextual    | ‚úÖ Yes       |

**Recommended Stack:**

- SessionStart ‚Üí Shows commands (0 tokens)
- Skills ‚Üí Suggest usage (contextual)
- UserPromptSubmit ‚Üí Detect intent (~20 tokens)

## [0.5.2] - 2025-10-25

**Status: Architecture Cleanup & Plugin Best Practices Release**

### Added

**Skills for Auto-Discovery:**

- `parallel-development-expert` - Proactively suggests parallelization when multiple tasks mentioned
- `intent-recognition` - Helps users discover Promptune capabilities
- Skills automatically activate based on user context (no manual invocation)
- Zero-config discovery mechanism

### Changed

**Plugin Architecture Improvements:**

- `/ctx:configure` - Converted from auto-modification to read-only guide
  - No longer automatically modifies user files (respects plugin boundaries)
  - Provides copy-paste snippets for optional manual customization
  - Explains trade-offs clearly (context cost vs benefits)
- Hook simplified to "suggest" mode only
  - Removed "verify" mode (sub-agent spawning)
  - Removed "auto" mode (auto-execution)
  - Hook now only adds context, Claude decides what to do
  - No user configuration needed (hardcoded behavior)

### Removed

- `/ctx:intents` command (unnecessary complexity)
- `commands/promptune-config.py` (Python dependency removed)
- `delegation_mode` configuration (no longer needed)
- `user_patterns.json` config file (hook has no configurable settings)
- Auto-modification of `~/.claude/CLAUDE.md` (anti-pattern)
- Auto-modification of `~/.claude/statusline.sh` (anti-pattern)

### Benefits

**Architecture:**

- ‚úÖ Plugin is self-contained (no user file modifications)
- ‚úÖ Skills provide automatic discovery (better than CLAUDE.md injection)
- ‚úÖ Hook is simpler and faster (removed branching logic)
- ‚úÖ Zero configuration required (works immediately after install)
- ‚úÖ Follows Claude Code plugin best practices

**User Experience:**

- ‚úÖ No setup needed - Skills activate automatically
- ‚úÖ Claude always in control (intelligent decision-making)
- ‚úÖ Lower context cost (~50 tokens vs 100s-1000s with sub-agents)
- ‚úÖ Cleaner install/uninstall (no orphaned user file modifications)

**Developer Experience:**

- ‚úÖ Simpler codebase (removed ~150 lines from hook)
- ‚úÖ No Python dependency for config (just Bash/Python for hook logic)
- ‚úÖ Easier to maintain (fewer modes, less complexity)

### Migration Notes

If you previously ran `/ctx:configure`:

1. Manually remove Promptune section from `~/.claude/CLAUDE.md` (optional)
2. Manually remove Promptune section from `~/.claude/statusline.sh` (optional)
3. Skills now provide discovery automatically (better than static context)

## [0.5.1] - 2025-10-25

**Status: Command Shortening & Research Release**

### Added

**New Command:**

- `/ctx:research` - Fast research using 3 parallel Haiku agents (1-2 min, ~$0.07)
  - Agent 1: Web research (latest trends, comparisons)
  - Agent 2: Codebase search (existing patterns, reuse opportunities)
  - Agent 3: Dependency analysis (what's installed, compatibility)
  - Returns comparison table + recommendation + next steps

**Shortened Command Names:**

- All commands shortened from `/promptune:*` to `/ctx:*` for faster typing
- `/ctx:configure` - Setup persistent visibility
- `/ctx:intents` - Configure intent detection
- `/ctx:research` - Quick research (NEW)
- `/ctx:plan` - Create parallel development plans
- `/ctx:execute` - Execute plans in parallel
- `/ctx:status` - Monitor parallel tasks
- `/ctx:cleanup` - Clean up worktrees
- `/ctx:stats` - View statistics
- `/ctx:verify` - Verify detected commands

### Changed

- Updated status bar to show correct command names: `/ctx:research | /ctx:plan | /ctx:execute`
- Updated CLAUDE.md with shortened names and research command
- Updated README and all documentation with new command names
- Plugin description updated to highlight quick research capability

### Benefits

- **Faster typing**: `/ctx:*` vs `/promptune:*` (60% shorter)
- **Quick research**: Answer technical questions in 1-2 min with parallel agents
- **Cost efficient**: Research costs ~$0.07 (3 Haiku agents vs 1 Sonnet ~$0.15)
- **Better UX**: Shorter commands more natural to type

## [0.5.0] - 2025-10-24

**Status: Discovery & Configuration Release - Multi-Layered Visibility**

### Added

**Configuration Command:**

- `/ctx:configure` - One-time setup for persistent visibility
- Integrates Promptune into CLAUDE.md (~150 tokens context at session start)
- Adds Promptune commands to status bar (zero context, always visible)
- Creates backups before modifications (safe rollback)
- Validates plugin settings and skills
- Comprehensive error handling and rollback instructions

**Architecture Improvements:**

- Multi-layered discovery system (CLAUDE.md + Status Bar + Skills + Hook)
- Documented optimal discovery patterns in `.plans/ARCHITECTURE_IMPROVEMENTS_v0.5.1.md`
- Configuration specification in `.plans/CONFIGURE_COMMAND_SPEC.md`
- Implementation plan for cost optimization features in `.plans/IMPLEMENTATION_PLAN_v0.5.0.md`

**Discovery Enhancements:**

- CLAUDE.md integration for session-start awareness
- Status bar integration for persistent UI visibility
- Comprehensive research on Claude Code plugin architecture
- Context optimization strategies (~350 tokens passive overhead)

### Benefits

- **Visibility**: Promptune always present through multiple mechanisms
- **Discoverability**: 95%+ users will see and discover features
- **Cost**: Minimal context overhead (~$0.001 per session)
- **User Control**: Requires permission, creates backups, provides rollback

### Documentation

- Complete configure command specification
- Discovery architecture analysis
- Context overhead analysis
- Implementation and testing guides

## [0.3.0] - 2025-10-21

**Status: Haiku Agent Architecture Release - 81% Cost Reduction + 2x Speedup**

### Added

**Three-Tier Intelligence Architecture:**

- Tier 1 (Skills): Sonnet for guidance and expertise (20% of work)
- Tier 2 (Orchestration): Sonnet for planning and coordination
- Tier 3 (Execution): Haiku agents for cost-optimized task execution (80% of work)
- **Result**: 81% cost reduction ($1,680/year ‚Üí $328/year for 1,200 workflows)
- **Result**: 2x performance improvement (Haiku 1-2s vs Sonnet 3-5s response time)

**Haiku Agents (5 Specialized Agents):**

- `parallel-task-executor`: Autonomous feature implementation ($0.04 vs $0.27 Sonnet)
- `worktree-manager`: Git worktree lifecycle management ($0.008 vs $0.06 Sonnet)
- `issue-orchestrator`: GitHub issue management ($0.01 vs $0.08 Sonnet)
- `test-runner`: Autonomous test execution and reporting ($0.02 vs $0.15 Sonnet)
- `performance-analyzer`: Workflow benchmarking and optimization ($0.015 vs $0.12 Sonnet)

**Cost Tracking & Optimization:**

- Real-time cost comparison (Sonnet vs Haiku)
- Cost savings dashboard in workflow reports
- ROI calculator for annual projections
- Cost per task/minute/workflow metrics
- CSV-based cost tracking system

**Enhanced Documentation:**

- `HAIKU_AGENT_ARCHITECTURE.md` - Complete three-tier architecture spec
- `AGENT_INTEGRATION_GUIDE.md` - Integration patterns and best practices
- `COST_OPTIMIZATION_GUIDE.md` - Cost tracking, ROI analysis, optimization strategies
- `MIGRATION_GUIDE_v0.3.0.md` - Upgrade guide from v0.2.0

### Changed

- Updated `promptune-parallel-execute` to use Haiku agents instead of generic Task tool
- Enhanced `performance-optimizer` skill with cost tracking capabilities
- Updated plugin.json to v0.3.0 with new description and keywords

### Performance

- **Cost**: 81% reduction per workflow (5 tasks: $0.274 vs $1.404)
- **Speed**: 2x faster agent response times
- **Scalability**: Same 200K context window as Sonnet
- **Quality**: Identical quality for execution tasks

### Documentation

- Added agent specifications (5 markdown files, ~90KB total)
- Added integration guides (2 markdown files, ~65KB)
- Updated Skills with cost optimization guidance
- Added cost tracking examples and calculators

## [0.2.0] - 2025-10-21

**Status: AI-Powered Skills Release**

### Added

**AI-Powered Skills (4 Autonomous Skills):**

- `parallel-development-expert`: Autonomous guidance on parallelizing development tasks
- `intent-recognition`: Helps users discover Promptune capabilities
- `git-worktree-master`: Expert troubleshooting for git worktree issues
- `performance-optimizer`: Analyzes and optimizes parallel workflow performance

**Skills Features:**

- Model-invoked (Claude decides when to activate based on context)
- Autonomous expert guidance without user having to ask
- Integration with parallel development workflows
- Comprehensive documentation and examples

**Enhanced Documentation:**

- `SKILLS_ENHANCEMENT.md` - Technical architecture of Skills system
- `QUICKSTART_SKILLS.md` - 5-minute quick start guide
- `skills/README.md` - Complete user guide for Skills
- Skills-specific documentation (4 markdown files, ~2,244 lines)

**Parallel Setup Optimization:**

- O(1) parallel setup (constant time regardless of task count)
- Each subagent creates own issue and worktree autonomously
- 30-63% faster setup time (5 tasks: 32s saved, 20 tasks: 152s saved)
- `PARALLEL_SETUP_PATTERN.md` documentation

### Changed

- Updated plugin.json to v0.2.0
- Updated README with prominent Skills section
- Enhanced `promptune-parallel-execute` with parallel setup pattern

### Documentation

- Skills architecture and integration guides
- Parallel setup optimization documentation
- Enhanced user documentation with Skills examples

## [0.1.0] - 2025-10-15

**Status: Beta Release**

### Added

- 3-tier detection cascade (Keyword ‚Üí Model2Vec ‚Üí Semantic Router)
- Keyword matching tier (0.02ms P95 latency, 60% coverage)
- Model2Vec embedding tier (0.2ms P95 latency, 30% coverage)
- Semantic Router tier (50ms P95 latency, 10% coverage)
- UserPromptSubmit hook for intent detection
- 26 command mappings out of the box
- Intent mappings for SuperClaude commands (`/sc:*`)
- Parallel development workflow commands:
  - `/ctx:plan` - Document development plans
  - `/ctx:execute` - Execute parallel development with git worktrees
  - `/ctx:status` - Monitor parallel task progress
  - `/ctx:cleanup` - Clean up completed worktrees
- Configuration command: `/ctx:intents`
- Statistics command: `/ctx:stats`
- Automatic subagent spawning for parallel execution
- GitHub integration (issue creation, labeling, tracking)
- Git worktree management for isolated development
- Custom pattern support via `user_patterns.json`
- Confidence scoring system
- Natural language aliases
- Context-aware keyword detection
- Lazy model loading for performance
- Comprehensive documentation (README, commands, architecture)
- MIT license
- MkDocs documentation site
- Testing suite with pytest
- Code quality tooling (ruff, mypy)
- UV package manager integration
- PEP 723 inline script metadata support

### Documentation

- Complete README with features, installation, usage
- Individual command documentation files
- Architecture documentation
- CLAUDE.md development guide
- PUBLISHING.md marketplace guide
- API documentation with mkdocstrings
- Troubleshooting guide
- Performance benchmarks

### Infrastructure

- GitHub repository setup
- Plugin manifest (plugin.json)
- Marketplace manifest (marketplace.json)
- Hooks configuration (hooks.json)
- Python project configuration (pyproject.toml)
- Git ignore configuration
- Code formatting and linting setup
- Type checking configuration
- Test infrastructure

## [0.0.1] - 2025-10-14

### Added

- Initial project structure
- Basic plugin scaffolding
- Development environment setup

[Unreleased]: https://github.com/promptunecc/promptune
[0.1.0]: https://github.com/promptunecc/promptune
[0.0.1]: https://github.com/promptunecc/promptune
